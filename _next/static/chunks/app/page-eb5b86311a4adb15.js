(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[974],{2858:(e,r,n)=>{"use strict";n.d(r,{k5:()=>d});var t=n(6636),s={color:void 0,size:void 0,className:void 0,style:void 0,attr:void 0},i=t.createContext&&t.createContext(s),a=["attr","size","title"];function o(){return(o=Object.assign?Object.assign.bind():function(e){for(var r=1;r<arguments.length;r++){var n=arguments[r];for(var t in n)Object.prototype.hasOwnProperty.call(n,t)&&(e[t]=n[t])}return e}).apply(this,arguments)}function l(e,r){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);r&&(t=t.filter(function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable})),n.push.apply(n,t)}return n}function c(e){for(var r=1;r<arguments.length;r++){var n=null!=arguments[r]?arguments[r]:{};r%2?l(Object(n),!0).forEach(function(r){var t,s,i;t=e,s=r,i=n[r],(s=function(e){var r=function(e,r){if("object"!=typeof e||!e)return e;var n=e[Symbol.toPrimitive];if(void 0!==n){var t=n.call(e,r||"default");if("object"!=typeof t)return t;throw TypeError("@@toPrimitive must return a primitive value.")}return("string"===r?String:Number)(e)}(e,"string");return"symbol"==typeof r?r:r+""}(s))in t?Object.defineProperty(t,s,{value:i,enumerable:!0,configurable:!0,writable:!0}):t[s]=i}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach(function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(n,r))})}return e}function d(e){return r=>t.createElement(h,o({attr:c({},e.attr)},r),function e(r){return r&&r.map((r,n)=>t.createElement(r.tag,c({key:n},r.attr),e(r.child)))}(e.child))}function h(e){var r=r=>{var n,{attr:s,size:i,title:l}=e,d=function(e,r){if(null==e)return{};var n,t,s=function(e,r){if(null==e)return{};var n={};for(var t in e)if(Object.prototype.hasOwnProperty.call(e,t)){if(r.indexOf(t)>=0)continue;n[t]=e[t]}return n}(e,r);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)n=i[t],!(r.indexOf(n)>=0)&&Object.prototype.propertyIsEnumerable.call(e,n)&&(s[n]=e[n])}return s}(e,a),h=i||r.size||"1em";return r.className&&(n=r.className),e.className&&(n=(n?n+" ":"")+e.className),t.createElement("svg",o({stroke:"currentColor",fill:"currentColor",strokeWidth:"0"},r.attr,s,d,{className:n,style:c(c({color:e.color||r.color},r.style),e.style),height:h,width:h,xmlns:"http://www.w3.org/2000/svg"}),l&&t.createElement("title",null,l),e.children)};return void 0!==i?t.createElement(i.Consumer,null,e=>r(e)):r(s)}},6137:(e,r,n)=>{Promise.resolve().then(n.bind(n,9165))},6897:(e,r)=>{"use strict";function n(){return null}Object.defineProperty(r,"__esModule",{value:!0}),Object.defineProperty(r,"default",{enumerable:!0,get:function(){return n}}),("function"==typeof r.default||"object"==typeof r.default&&null!==r.default)&&void 0===r.default.__esModule&&(Object.defineProperty(r.default,"__esModule",{value:!0}),Object.assign(r.default,r),e.exports=r.default)},9165:(e,r,n)=>{"use strict";n.r(r),n.d(r,{default:()=>l});var t=n(6384),s=n(6897),i=n.n(s),a=n(6636),o=n(3448);function l(){let[e,r]=(0,a.useState)(!1);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(i(),{children:[(0,t.jsx)("title",{children:"RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination"}),(0,t.jsx)("meta",{name:"description",content:"We present RenderFormer, a neural rendering pipeline that directly renders an image from a triangle-based representation of scene with full global illumination effects, and that does not require per-scene training or finetuning."}),(0,t.jsx)("meta",{name:"keywords",content:"RenderFormer, Neural Rendering, Rendering, Global Illumination, Sequence-to-Sequence, Transformer"}),(0,t.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1"})]}),(0,t.jsxs)("div",{className:"site-container",children:[(0,t.jsx)("nav",{className:"top-nav",children:(0,t.jsxs)("div",{className:"nav-content",children:[(0,t.jsx)("div",{className:"logo",children:"RF"}),(0,t.jsxs)("div",{className:"nav-links",children:[(0,t.jsx)("a",{href:"#intro",children:"Introduction"}),(0,t.jsx)("a",{href:"#BibTeX",children:"BibTeX"})]})]})}),(0,t.jsx)("header",{className:"main-header",children:(0,t.jsxs)("div",{className:"header-grid",children:[(0,t.jsxs)("div",{className:"title-area",children:[(0,t.jsx)("h1",{className:"main-title",children:(0,t.jsx)("span",{className:"title-highlight",children:"RenderFormer"})}),(0,t.jsx)("h2",{className:"subtitle",children:"Transformer-based Neural Rendering of Triangle Meshes with Global Illumination"}),(0,t.jsx)("div",{className:"conference-badge",children:"SIGGRAPH 2025"}),(0,t.jsxs)("div",{className:"authors-list",children:[(0,t.jsxs)("a",{href:"https://www.chong-zeng.com/",className:"author",children:["Chong Zeng",(0,t.jsx)("sup",{children:"1,2"})]}),(0,t.jsxs)("a",{href:"https://yuedong.shading.me/",className:"author",children:["Yue Dong",(0,t.jsx)("sup",{children:"2"})]}),(0,t.jsxs)("a",{href:"https://www.cs.wm.edu/~ppeers/",className:"author",children:["Pieter Peers",(0,t.jsx)("sup",{children:"3"})]}),(0,t.jsxs)("a",{href:"https://svbrdf.github.io/",className:"author",children:["Hongzhi Wu",(0,t.jsx)("sup",{children:"1"})]}),(0,t.jsxs)("a",{href:"https://scholar.google.com/citations?user=P91a-UQAAAAJ&hl=en",className:"author",children:["Xin Tong",(0,t.jsx)("sup",{children:"2"})]})]}),(0,t.jsxs)("div",{className:"affiliations",children:[(0,t.jsxs)("div",{className:"affiliation",children:[(0,t.jsx)("sup",{children:"1"}),"State Key Lab of CAD and CG, Zhejiang University"]}),(0,t.jsxs)("div",{className:"affiliation",children:[(0,t.jsx)("sup",{children:"2"}),"Microsoft Research Asia"]}),(0,t.jsxs)("div",{className:"affiliation",children:[(0,t.jsx)("sup",{children:"3"}),"College of William & Mary"]})]}),(0,t.jsxs)("div",{className:"cta-buttons",children:[(0,t.jsxs)("a",{href:"#",className:"cta-button",children:[(0,t.jsx)(o.jH2,{size:18,className:"icon"})," Paper"]}),(0,t.jsxs)("a",{href:"https://github.com/microsoft/renderformer",className:"cta-button",children:[(0,t.jsx)(o.BR8,{size:18,className:"icon"})," Code"]})]})]}),(0,t.jsx)("div",{className:"header-image-container"})]})}),(0,t.jsx)("section",{id:"intro",className:"section abstract-section",children:(0,t.jsxs)("div",{className:"section-container",children:[(0,t.jsx)("h2",{className:"section-title",children:"Introduction"}),(0,t.jsx)("div",{className:"abstract-content",children:(0,t.jsxs)("p",{children:["We present RenderFormer, a neural rendering pipeline that directly renders an image from a triangle-based representation of a scene with full global illumination effects and that ",(0,t.jsx)("strong",{children:"does not require per-scene training or fine-tuning"}),"."]})}),(0,t.jsx)("h3",{className:"subsection-title",children:"Mesh to Image, End to End"}),(0,t.jsxs)("p",{children:["Instead of taking a physics-centric approach to rendering, we formulate rendering as a ",(0,t.jsx)("strong",{children:"sequence-to-sequence transformation"})," where a sequence of tokens representing triangles with reflectance properties is converted to a sequence of output tokens representing small patches of pixels."]}),(0,t.jsx)("h3",{className:"subsection-title",children:"Simple Transformer Architecture with Minimal Prior Constraints"}),(0,t.jsxs)("p",{children:["RenderFormer follows a two stage pipeline: a view-independent stage that models triangle-to-triangle light transport, and a view-dependent stage that transforms a token representing a bundle of rays to the corresponding pixel values guided by the triangle-sequence from the the view-independent stage. Both stages are based on the transformer architecture and are learned with minimal prior constraints. ",(0,t.jsx)("strong",{children:"No rasterization, no ray tracing."})]})]})}),(0,t.jsx)("section",{id:"BibTeX",className:"section bibtex-section",children:(0,t.jsxs)("div",{className:"section-container",children:[(0,t.jsx)("h2",{className:"section-title",children:"BibTeX"}),(0,t.jsxs)("div",{className:"bibtex-wrapper",children:[(0,t.jsx)("div",{className:"bibtex-container",children:(0,t.jsx)("pre",{className:"bibtex-code",children:(0,t.jsx)("code",{children:"@inproceedings {zeng2025renderformer,\n    title      = {RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination},\n    author     = {Chong Zeng and Yue Dong and Pieter Peers and Hongzhi Wu and Xin Tong},\n    booktitle  = {ACM SIGGRAPH 2025 Conference Papers},\n    year       = {2025}\n}"})})}),(0,t.jsx)("button",{className:"copy-button",onClick:()=>{navigator.clipboard.writeText("@inproceedings {zeng2025renderformer,\n    title      = {RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination},\n    author     = {Chong Zeng and Yue Dong and Pieter Peers and Hongzhi Wu and Xin Tong},\n    booktitle  = {ACM SIGGRAPH 2025 Conference Papers},\n    year       = {2025}\n}").then(()=>{r(!0),setTimeout(()=>r(!1),2e3)})},children:e?(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(o.YrT,{size:16,className:"icon"})," Copied!"]}):(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(o.nxz,{size:16,className:"icon"})," Copy"]})})]})]})}),(0,t.jsx)("footer",{className:"footer",children:(0,t.jsxs)("div",{className:"footer-content",children:[(0,t.jsxs)("div",{className:"footer-links",children:[(0,t.jsx)("a",{href:"https://go.microsoft.com/fwlink/?LinkId=521839",children:"Privacy & Cookies"}),(0,t.jsx)("a",{href:"https://go.microsoft.com/fwlink/?LinkID=2259814",children:"Consumer Health Privacy"}),(0,t.jsx)("a",{href:"https://go.microsoft.com/fwlink/?LinkID=206977",children:"Terms of Use"}),(0,t.jsx)("a",{href:"https://www.microsoft.com/trademarks",children:"Trademarks"})]}),(0,t.jsx)("div",{className:"footer-copyright",children:"\xa9 2025 Microsoft"})]})})]})]})}}},e=>{var r=r=>e(e.s=r);e.O(0,[215,309,951,358],()=>r(6137)),_N_E=e.O()}]);