<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/dvslredstestwebsite/_next/static/css/b88af8d26f11986e.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/dvslredstestwebsite/_next/static/chunks/webpack-9b4b8ca3bb59aae0.js"/><script src="/dvslredstestwebsite/_next/static/chunks/09f5f10c-545a618be3c169c6.js" async=""></script><script src="/dvslredstestwebsite/_next/static/chunks/951-2f6cf8be7126f7b6.js" async=""></script><script src="/dvslredstestwebsite/_next/static/chunks/main-app-ca94d6bb600fba59.js" async=""></script><script src="/dvslredstestwebsite/_next/static/chunks/1951f239-803c5e83ae01d4ac.js" async=""></script><script src="/dvslredstestwebsite/_next/static/chunks/app/page-eb5b86311a4adb15.js" async=""></script><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/dvslredstestwebsite/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><div class="site-container"><nav class="top-nav"><div class="nav-content"><div class="logo">RF</div><div class="nav-links"><a href="#intro">Introduction</a><a href="#BibTeX">BibTeX</a></div></div></nav><header class="main-header"><div class="header-grid"><div class="title-area"><h1 class="main-title"><span class="title-highlight">RenderFormer</span></h1><h2 class="subtitle">Transformer-based Neural Rendering of Triangle Meshes with Global Illumination</h2><div class="conference-badge">SIGGRAPH 2025</div><div class="authors-list"><a href="https://www.chong-zeng.com/" class="author">Chong Zeng<sup>1,2</sup></a><a href="https://yuedong.shading.me/" class="author">Yue Dong<sup>2</sup></a><a href="https://www.cs.wm.edu/~ppeers/" class="author">Pieter Peers<sup>3</sup></a><a href="https://svbrdf.github.io/" class="author">Hongzhi Wu<sup>1</sup></a><a href="https://scholar.google.com/citations?user=P91a-UQAAAAJ&amp;hl=en" class="author">Xin Tong<sup>2</sup></a></div><div class="affiliations"><div class="affiliation"><sup>1</sup>State Key Lab of CAD and CG, Zhejiang University</div><div class="affiliation"><sup>2</sup>Microsoft Research Asia</div><div class="affiliation"><sup>3</sup>College of William &amp; Mary</div></div><div class="cta-buttons"><a href="#" class="cta-button"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="icon" height="18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg> Paper</a><a href="https://github.com/microsoft/renderformer" class="cta-button"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="icon" height="18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg> Code</a></div></div><div class="header-image-container"></div></div></header><section id="intro" class="section abstract-section"><div class="section-container"><h2 class="section-title">Introduction</h2><div class="abstract-content"><p>We present RenderFormer, a neural rendering pipeline that directly renders an image from a triangle-based representation of a scene with full global illumination effects and that <strong>does not require per-scene training or fine-tuning</strong>.</p></div><h3 class="subsection-title">Mesh to Image, End to End</h3><p>Instead of taking a physics-centric approach to rendering, we formulate rendering as a <strong>sequence-to-sequence transformation</strong> where a sequence of tokens representing triangles with reflectance properties is converted to a sequence of output tokens representing small patches of pixels.</p><h3 class="subsection-title">Simple Transformer Architecture with Minimal Prior Constraints</h3><p>RenderFormer follows a two stage pipeline: a view-independent stage that models triangle-to-triangle light transport, and a view-dependent stage that transforms a token representing a bundle of rays to the corresponding pixel values guided by the triangle-sequence from the the view-independent stage. Both stages are based on the transformer architecture and are learned with minimal prior constraints. <strong>No rasterization, no ray tracing.</strong></p></div></section><section id="BibTeX" class="section bibtex-section"><div class="section-container"><h2 class="section-title">BibTeX</h2><div class="bibtex-wrapper"><div class="bibtex-container"><pre class="bibtex-code"><code>@inproceedings {zeng2025renderformer,
    title      = {RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination},
    author     = {Chong Zeng and Yue Dong and Pieter Peers and Hongzhi Wu and Xin Tong},
    booktitle  = {ACM SIGGRAPH 2025 Conference Papers},
    year       = {2025}
}</code></pre></div><button class="copy-button"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="icon" height="16" width="16" xmlns="http://www.w3.org/2000/svg"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg> Copy</button></div></div></section><footer class="footer"><div class="footer-content"><div class="footer-links"><a href="https://go.microsoft.com/fwlink/?LinkId=521839">Privacy &amp; Cookies</a><a href="https://go.microsoft.com/fwlink/?LinkID=2259814">Consumer Health Privacy</a><a href="https://go.microsoft.com/fwlink/?LinkID=206977">Terms of Use</a><a href="https://www.microsoft.com/trademarks">Trademarks</a></div><div class="footer-copyright">Â© 2025 Microsoft</div></div></footer></div><!--$--><!--/$--><!--$--><!--/$--><script src="/dvslredstestwebsite/_next/static/chunks/webpack-9b4b8ca3bb59aae0.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7028,[],\"\"]\n3:I[1698,[],\"\"]\n4:I[2241,[],\"ClientPageRoot\"]\n5:I[9165,[\"215\",\"static/chunks/1951f239-803c5e83ae01d4ac.js\",\"974\",\"static/chunks/app/page-eb5b86311a4adb15.js\"],\"default\"]\n8:I[8948,[],\"MetadataBoundary\"]\na:I[8948,[],\"OutletBoundary\"]\nd:I[2140,[],\"AsyncMetadataOutlet\"]\nf:I[8948,[],\"ViewportBoundary\"]\n11:I[1051,[],\"\"]\n:HL[\"/dvslredstestwebsite/_next/static/css/b88af8d26f11986e.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"WH8qJFWO8URQW5qNlfZuG\",\"p\":\"/dvslredstestwebsite\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/dvslredstestwebsite/_next/static/css/b88af8d26f11986e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{}],[\"$\",\"body\",null,{\"suppressHydrationWarning\":true,\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"$L4\",null,{\"Component\":\"$5\",\"searchParams\":{},\"params\":{},\"promises\":[\"$@6\",\"$@7\"]}],[\"$\",\"$L8\",null,{\"children\":\"$L9\"}],null,[\"$\",\"$La\",null,{\"children\":[\"$Lb\",\"$Lc\",[\"$\",\"$Ld\",null,{\"promise\":\"$@e\"}]]}]]}],{},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"7rmjfj9bo8WWVa0Qk-YTT\",{\"children\":[[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],null]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"12:\"$Sreact.suspense\"\n13:I[2140,[],\"AsyncMetadata\"]\n6:{}\n7:{}\n9:[\"$\",\"$12\",null,{\"fallback\":null,\"children\":[\"$\",\"$L13\",null,{\"promise\":\"$@14\"}]}]\n"])</script><script>self.__next_f.push([1,"c:null\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nb:null\n"])</script><script>self.__next_f.push([1,"14:{\"metadata\":[],\"error\":null,\"digest\":\"$undefined\"}\ne:{\"metadata\":\"$14:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>