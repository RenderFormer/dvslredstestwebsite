<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="We present RenderFormer, a neural rendering pipeline that directly renders an image from a triangle-based representation of scene with full global illumination effects, and that does not require per-scene training or finetuning.">
  <meta name="keywords" content="RenderFormer, Neural Rendering, Rendering, Global Illumination, Sequence-
  to-Sequence, Transformer">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination</title>

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script defer src="./static/js/fontawesome.all.min.js" charset="utf-8"></script>

  <script>
    document.addEventListener('DOMContentLoaded', () => {
      const modal = document.getElementById('infoModal');
      const openBtn = document.getElementById('openModal');
      const closeBtn = modal.querySelector('.modal-close');
      const modalBackground = modal.querySelector('.modal-background');

      openBtn.addEventListener('click', () => {
        modal.classList.add('is-active');
      });

      closeBtn.addEventListener('click', () => {
        modal.classList.remove('is-active');
      });

      modalBackground.addEventListener('click', () => {
        modal.classList.remove('is-active');
      });
    });
  </script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Neural Rendering Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://nrhints.github.io/">
              NRHints
            </a>
            <a class="navbar-item" href="https://dilightnet.github.io/">
              DiLightNet
            </a>
            <a class="navbar-item" href="https://gsrelight.github.io/">
              GS^3
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination
            </h1>
            <h2 class="subtitle is-size-4 publication-venue">SIGGRAPH 2025</h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://www.chong-zeng.com/">Chong Zeng</a><sup>1,2</sup>,</span>
              <span class="author-block">
                <a href="https://yuedong.shading.me/">Yue Dong</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.cs.wm.edu/~ppeers/">Pieter Peers</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="https://svbrdf.github.io/">Hongzhi Wu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=P91a-UQAAAAJ&hl=en">Xin Tong</a><sup>2</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>State Key Lab of CAD and CG, Zhejiang University</span>
              <span class="author-block"><sup>2</sup>Microsoft Research Asia</span>
              <span class="author-block"><sup>3</sup>College of William & Mary</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper (Coming Soon)</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img src="./imgs/rep.jpg" alt="Rendering results with RenderFormer"/>
        <h2 class="subtitle has-text-centered">
          Examples of triangle-mesh based scenes rendered with RenderFormer without per-scene training or fine-tuning that include (multiple) specular reflections, complex shadows with details finer than a triangle, diffuse indirect lighting, glossy reflections, soft and hard shadows, and multiple light sources.
        </h2>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              We present RenderFormer, a neural rendering pipeline that directly renders an image from a triangle-based representation of a scene with full global illumination effects and that does not require per-scene training or fine-tuning. Instead of taking a physics-centric approach to rendering, we formulate rendering as a sequence-to-sequence transformation where a sequence of tokens representing triangles with reflectance properties is converted to a sequence of output tokens representing small patches of pixels. RenderFormer follows a two stage pipeline: a view-independent stage that models triangle-to-triangle light transport, and a view-dependent stage that transforms a token representing a bundle of rays to the corresponding pixel values guided by the triangle-sequence from the the view-independent stage. Both stages are based on the transformer architecture and are learned with minimal prior constraints. We demonstrate and evaluate RenderFormer on scenes with varying complexity in shape and light transport.
            </p>
          </div>
        </div>
      </div>
      <img src="./imgs/model-arch.png" alt="Model architecture" />
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <!-- <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
          <iframe src="" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
        </div>
      </div> -->
      <!--/ Paper video. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Videos</h2>
        <p></p>
      </div>

      <div class="columns is-centered has-text-centered">
        <div class="column">
          <div class="columns is-centered has-text-centered">
            <div class="column content">
              <video id="matting-video" autoplay muted loop playsinline height="100%">
                <source src="./videos/tree-rot-obj.mp4" type="video/mp4">
              </video>
              <p>
                Tree Object Rotation
              </p>
            </div>
          </div>
        </div>
        <div class="column">
          <div class="columns is-centered has-text-centered">
            <div class="column content">
              <video id="matting-video" autoplay muted loop playsinline height="100%">
                <source src="./videos/tree-change-light.mp4" type="video/mp4">
              </video>
              <p>
                Tree Light Change
              </p>
            </div>
          </div>
        </div>
        <div class="column">
          <div class="columns is-centered has-text-centered">
            <div class="column content">
              <video id="matting-video" autoplay muted loop playsinline height="100%">
                <source src="./videos/constant-width-fancy.mp4" type="video/mp4">
              </video>
              <p>
                Fancy Scene
              </p>
            </div>
          </div>
        </div>
      </div>

      <div class="columns is-centered has-text-centered">
        <div class="column">
          <div class="columns is-centered has-text-centered">
            <div class="column content">
              <video id="matting-video" autoplay muted loop playsinline height="100%">
                <source src="./videos/compose-change-light.mp4" type="video/mp4">
              </video>
              <p>
                Composed Scene Light Change
              </p>
            </div>
          </div>
        </div>
        <div class="column">
          <div class="columns is-centered has-text-centered">
            <div class="column content">
              <video id="matting-video" autoplay muted loop playsinline height="100%">
                <source src="./videos/cbox-backwall-roughness-change.mp4" type="video/mp4">
              </video>
              <p>
                Cornell Box Roughness Adjustment
              </p>
            </div>
          </div>
        </div>
        <div class="column">
          <div class="columns is-centered has-text-centered">
            <div class="column content">
              <video id="matting-video" autoplay muted loop playsinline height="100%">
                <source src="./videos/bunny-roughness.mp4" type="video/mp4">
              </video>
              <p>
                Bunny Roughness Adjustment
              </p>
            </div>
          </div>
        </div>
      </div>

    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings {zeng2025renderformer,
    title      = {RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination},
    author     = {Chong Zeng and Yue Dong and Pieter Peers and Hongzhi Wu and Xin Tong},
    booktitle  = {ACM SIGGRAPH 2025 Conference Papers},
    year       = {2025}
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
                <div class="footer__copyright"><p class="text-center">
                  <a href="https://go.microsoft.com/fwlink/?LinkId=521839" style="color: 1677b6;">Privacy &amp; Cookies</a> |
                  <a href="https://go.microsoft.com/fwlink/?LinkID=2259814" style="color: 1677b6;">Consumer Health Privacy</a> |
                  <a href="https://go.microsoft.com/fwlink/?LinkID=206977" style="color: 1677b6;">Terms of Use</a> |
                  <a href="https://www.microsoft.com/trademarks" style="color: 1677b6;">Trademarks</a> | © 2025 Microsoft.
                  </p></div></div></div></footer></div>
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>